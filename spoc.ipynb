{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spoc.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "scPaTfo7Nd28"
      },
      "source": [
        "!nvidia-smi # You want 16280MiB, just hardreset runtime and run again."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_jTFs5vNwg9"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir /content/GeneratedDataset\n",
        "!mkdir /content/GeneratedDataset/GeneratedImagesCurrent\n",
        "!mkdir /content/GeneratedDataset/GeneratedImagesXmlCurrent\n",
        "!mkdir /content/GeneratedDataset/GeneratedImagesNew\n",
        "!mkdir /content/GeneratedDataset/GeneratedImagesXmlNew\n",
        "\n",
        "!wget https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz\n",
        "!tar xf dtd-r1.0.1.tar.gz\n",
        "!rm /content/dtd-r1.0.1.tar.gz\n",
        "\n",
        "!git clone https://github.com/AIWintermuteAI/aXeleRate.git\n",
        "!pip uninstall -y imgaug && pip uninstall -y albumentations && pip install imgaug==0.4\n",
        "\n",
        "%cd /content/\n",
        "!mkdir /content/Yolo-digit-detector\n",
        "%cd /content/Yolo-digit-detector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybb6PayoOdW4"
      },
      "source": [
        "%cd /content\n",
        "from keras import backend as K\n",
        "import sys\n",
        "sys.path.append('/content/aXeleRate')\n",
        "from axelerate import setup_training, setup_inference\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgGlr4ZnO-aE"
      },
      "source": [
        "# Satellite sends down I have taken a picture at the time xx: xx: xx\n",
        "# Lab sends data on all boats' positions at time xx: xx: xx\n",
        "# Satellite receives the annotations and places them on its \"rolling\" training set. Pops oldest image and append latest."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsjx7Uw4ZzIo"
      },
      "source": [
        "class Annotation_lab:\n",
        "    def __init__(self, data):\n",
        "        self.data = data                                                                                # Hold all data of type dictionary TIME : { LABEL: COORD, SIZE }\n",
        "        self.satelites = []                                                                             # Array of all satelites that whish to comunicate with this lab\n",
        "\n",
        "    def send_annotation(self, time, label):\n",
        "        data_from_labels = { }\n",
        "        for key, value in self.data[time].items():\n",
        "            if str(key) in label:\n",
        "                data_from_labels.update({key: value})\n",
        "\n",
        "        return data_from_labels\n",
        "        # return self.data[time][label]                                                                   # Sends all annotations of this label at given time\n",
        "\n",
        "    def add_data(self, data):\n",
        "        self.data.update(data)                                                                          # Of type dictionary TIME : { LABEL: COORD, SIZE }<\n",
        "\n",
        "    def add_satelite(self, satelite):\n",
        "        self.satelites.append(satelite)                                                                 # Adds satelite\n",
        "\n",
        "    def aggregate_weights(self): # Aggregates all weights from each satelite and sends aggregated weights back\n",
        "        weighted_sum\n",
        "        for satelite in self.satelites:\n",
        "            weighted_sum += satelite.send_weight()\n",
        "\n",
        "        for satelite in self.satelites:\n",
        "            satelite.download_weight(weighted_sum)\n",
        "\n",
        "import xml.etree.cElementTree as ET\n",
        "import cv2\n",
        "from keras import backend as K\n",
        "from axelerate import setup_training, setup_inference\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "\n",
        "class Satelite:\n",
        "    def get_config(self, model_path, architecture, batch_size, saved_folder, train_times, actual_epoch, learning_rate, labels):\n",
        "        config = {\n",
        "            \"model\":{\n",
        "                \"type\":             \"Detector\",\n",
        "                \"architecture\":     architecture,\n",
        "                \"input_size\":       2000,         # 123 prolly will have to crop image around annotation\n",
        "                \"anchors\":          [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],\n",
        "                \"labels\":           labels,\n",
        "                \"coord_scale\" : \t\t1.0,\n",
        "                \"class_scale\" : \t\t1.0,\n",
        "                \"object_scale\" : \t\t5.0,\n",
        "                \"no_object_scale\" : 1.0\n",
        "            },\n",
        "            \"weights\" : {\n",
        "                \"full\":   \t\t\t\t  model_path,\n",
        "                \"backend\":   \t\t    \"imagenet\"\n",
        "            },\n",
        "            \"train\" : {\n",
        "                \"actual_epoch\":         actual_epoch,\n",
        "                \"train_image_folder\":   \"/content/GeneratedDataset/GeneratedImagesCurrent\",\n",
        "                \"train_annot_folder\":   \"/content/GeneratedDataset/GeneratedImagesXmlCurrent\",\n",
        "                \"train_times\":          train_times,\n",
        "                \"valid_image_folder\":   \"/content/GeneratedDataset/GeneratedImagesNew\",\n",
        "                \"valid_annot_folder\":   \"/content/GeneratedDataset/GeneratedImagesXmlNew\",\n",
        "                \"valid_times\":          1,\n",
        "                \"valid_metric\":         \"mAP\",\n",
        "                \"batch_size\":           batch_size,\n",
        "                \"learning_rate\":        learning_rate,\n",
        "                \"saved_folder\":   \t    saved_folder,\n",
        "                \"first_trainable_layer\":\"\",\n",
        "                \"augumentation\":\t\t\t\tFalse,\n",
        "                \"is_only_detect\" : \t\t  False\n",
        "            },\n",
        "            \"converter\" : {\n",
        "                \"type\":   \t\t\t\t[\"k210\",\"kmodel\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return config\n",
        "\n",
        "    def __init__(self, annotation_lab, train_times_per_dataset, labels, actual_epoch, learning_rate):\n",
        "        self.annotation_lab = annotation_lab                                                            # Simulated annotation lab that holds all data\n",
        "\n",
        "        self.labels = labels                                                                            # Labels that we train on\n",
        "\n",
        "        # self.current_image_dataset_dir = \"/content/GeneratedDataset/GeneratedImagesCurrent\"             # Folder holding current training dataset\n",
        "        # self.current_annotation_dataset_dir = \"/content/GeneratedDataset/GeneratedImagesXmlCurrent\"     # - || -\n",
        "        # self.train_time = train_times_per_dataset                                                       # After you have trained train_time's delete current_image_dataset_dir and copy over this dataset:\n",
        "        # self.new_image_dataset_dir = \"/content/GeneratedDataset/GeneratedImagesNew\"                     # Folder to append new accumulated training data\n",
        "        # self.new_annotation_dataset_dir = \"/content/GeneratedDataset/GeneratedImagesXmlNew\"             # - || -\n",
        "\n",
        "        path_10x10_2 = '/content/drive/MyDrive/agriculture_1_2019_500_500_1000_1000.nc'\n",
        "        self.nc_dataset = xr.open_dataset(path_10x10_2, chunks={\"time\": 10})\n",
        "\n",
        "        self.config = self.get_config(\"/content/GeneratedDataset\", \"MobileNet1_0\", 128, \"/content/GeneratedDataset\", train_times_per_dataset, actual_epoch, learning_rate, labels)\n",
        "\n",
        "    def take_new_image(self, time_stamp):                                                        # Acts that new image was taken\n",
        "        # Extract image from self.nc_dataset like eric did at this timestamp\n",
        "        # We have to read in image because we cant take an actual image\n",
        "\n",
        "        loaded_image = self.nc_dataset[[\"B04_10m\", \"B03_10m\", \"B02_10m\"]].isel(time=time_stamp)\n",
        "        img = loaded_image.to_array().plot.imshow(size=10,vmin=0, vmax=2500)\n",
        "\n",
        "        image_dir = self.config[\"train\"][\"valid_image_folder\"] + \"/{}.JPEG\".format(time_stamp)        # Dir to new dataset        \n",
        "        \n",
        "        plt.axis('tight')\n",
        "        img.set_cmap('hot')\n",
        "        plt.axis('off')\n",
        "        plt.axis('off')\n",
        "        plt.savefig(image_dir, bbox_inches='tight')\n",
        "\n",
        "        shape = [2000, 2000]\n",
        "\n",
        "        self.request_annotation(shape, time_stamp)                                              # \n",
        "\n",
        "    def request_annotation(self, image_shape, time_stamp):\n",
        "      #print(image_shape)\n",
        "      def create_root(file_prefix, image_shape):\n",
        "          root = ET.Element(\"annotations\")\n",
        "          ET.SubElement(root, \"filename\").text = \"{}.JPEG\".format(file_prefix)\n",
        "          ET.SubElement(root, \"folder\").text = \"images\"\n",
        "          size = ET.SubElement(root, \"size\")\n",
        "          ET.SubElement(size, \"width\").text = str(image_shape[0])\n",
        "          ET.SubElement(size, \"height\").text = str(image_shape[1])\n",
        "          ET.SubElement(size, \"depth\").text = \"3\"\n",
        "          return root\n",
        "      \n",
        "      def create_object_annotation(root, voc_labels):\n",
        "          for key, value in voc_labels.items():\n",
        "              for val in value:\n",
        "                  obj = ET.SubElement(root, \"object\")\n",
        "                  ET.SubElement(obj, \"name\").text = key\n",
        "                  ET.SubElement(obj, \"pose\").text = \"Unspecified\"\n",
        "                  ET.SubElement(obj, \"truncated\").text = str(0)\n",
        "                  ET.SubElement(obj, \"difficult\").text = str(0)\n",
        "                  bbox = ET.SubElement(obj, \"bndbox\")\n",
        "\n",
        "                  middle = val[0]\n",
        "                  size = val[1]\n",
        "\n",
        "                  #print(middle)\n",
        "                  #print(size)\n",
        "\n",
        "                  ET.SubElement(bbox, \"xmin\").text = str(middle[0] - (float(size[0]) * 0.5))\n",
        "                  ET.SubElement(bbox, \"ymin\").text = str(middle[1] - (float(size[1]) * 0.5))\n",
        "                  ET.SubElement(bbox, \"xmax\").text = str(middle[0] + (float(size[0]) * 0.5))\n",
        "                  ET.SubElement(bbox, \"ymax\").text = str(middle[1] + (float(size[1]) * 0.5))\n",
        "          return root\n",
        "\n",
        "      root = create_root(time_stamp, image_shape)                                                         # \n",
        "      root = create_object_annotation(root, annotation_lab.send_annotation(str(time_stamp), self.labels))      # \n",
        "      tree = ET.ElementTree(root)                                                                         # \n",
        "      tree.write(self.config[\"train\"][\"valid_annot_folder\"] + \"/{}.xml\".format(time_stamp))               # \n",
        "\n",
        "      # does not right now process world_coords to pixel_coords, it takes raw data from lab\n",
        "\n",
        "    # def add_annotation_to_list(label, coord1, coord2):\n",
        "    #     return [label, coord1, coord2]\n",
        "\n",
        "    def switch_validation_training(self):\n",
        "        # switch the training dirs with each other\n",
        "        # delete old data\n",
        "\n",
        "        def delete_in_folder(folder):\n",
        "            for filename in os.listdir(folder):\n",
        "                file_path = os.path.join(folder, filename)\n",
        "                try:\n",
        "                    if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                        os.unlink(file_path)\n",
        "                    elif os.path.isdir(file_path):\n",
        "                        shutil.rmtree(file_path)\n",
        "                except Exception as e:\n",
        "                    print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "        train_image_folder = self.config[\"train\"][\"train_image_folder\"]\n",
        "        train_annot_folder = self.config[\"train\"][\"train_annot_folder\"]\n",
        "        delete_in_folder(train_image_folder)\n",
        "        delete_in_folder(train_annot_folder)\n",
        "        \n",
        "        valid_image_folder = self.config[\"train\"][\"valid_image_folder\"]\n",
        "        valid_annot_folder = self.config[\"train\"][\"valid_annot_folder\"]\n",
        "\n",
        "        self.config[\"train\"][\"train_image_folder\"] = valid_image_folder\n",
        "        self.config[\"train\"][\"train_annot_folder\"] = valid_annot_folder\n",
        "        self.config[\"train\"][\"valid_image_folder\"] = train_image_folder\n",
        "        self.config[\"train\"][\"valid_annot_folder\"] = train_annot_folder\n",
        "\n",
        "    def train(self):\n",
        "        \n",
        "\n",
        "        # train\n",
        "        # K.clear_session()\n",
        "        # model_path = setup_training(config_dict=self.config)\n",
        "        print(\"implementation was not sufficient\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqacUyldwrYY"
      },
      "source": [
        "# Create virtual annotation_lab\n",
        "\n",
        "data_block = {\n",
        "\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"1\": {\n",
        "        \"house\": [\n",
        "        # Coordinate    width-height\n",
        "            [[92, 10], [20, 20]],\n",
        "            [[82, 60], [20, 20]]\n",
        "        ]\n",
        "    },\n",
        "    \"2\": {\n",
        "        \"house\": [\n",
        "        # Coordinate    width-height\n",
        "            [[92, 10], [20, 20]],\n",
        "            [[82, 60], [20, 20]]\n",
        "        ]\n",
        "    },\n",
        "    \"3\": {\n",
        "        \"house\": [\n",
        "        # Coordinate    width-height\n",
        "            [[92, 10], [20, 20]],\n",
        "            [[82, 60], [20, 20]]\n",
        "        ]\n",
        "    },\n",
        "    \"4\": {\n",
        "        \"house\": [\n",
        "        # Coordinate    width-height\n",
        "            [[92, 10], [20, 20]],\n",
        "            [[82, 60], [20, 20]]\n",
        "        ]\n",
        "    },\n",
        "    \"5\": {\n",
        "        \"house\": [\n",
        "        # Coordinate    width-height\n",
        "            [[92, 10], [20, 20]],\n",
        "            [[82, 60], [20, 20]]\n",
        "        ]\n",
        "    },\n",
        "    \"6\": {\n",
        "        \"house\": [\n",
        "        # Coordinate    width-height\n",
        "            [[92, 10], [20, 20]],\n",
        "            [[82, 60], [20, 20]]\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "annotation_lab = Annotation_lab(data_block)\n",
        "annotation_lab.add_data(data)\n",
        "\n",
        "print(annotation_lab.send_annotation(\"1\", [\"house\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_5g6MVbwwKz"
      },
      "source": [
        "# Create satelite annotation_lab, train_times_per_dataset, labels, actual_epoch, learning_rate\n",
        "satelite = Satelite(annotation_lab, 5, [\"house\"], 1, 1e-4)\n",
        "annotation_lab.add_satelite(satelite)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIOSKQEsbaEe"
      },
      "source": [
        "# Simulate taking picture on satelite\n",
        "satelite.take_new_image(1)\n",
        "satelite.take_new_image(2)\n",
        "\n",
        "satelite.switch_validation_training()\n",
        "satelite.take_new_image(3)\n",
        "satelite.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw-PkkWjVUi9"
      },
      "source": [
        "# Simulate taking picture on satelite\n",
        "satelite.take_new_image(4)\n",
        "satelite.take_new_image(5)\n",
        "\n",
        "satelite.switch_validation_training()\n",
        "satelite.take_new_image(6)\n",
        "satelite.train()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}